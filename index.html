<!DOCTYPE html>
<html lang="en" class="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CaptnReverse - Advanced OCR & TTS</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://unpkg.com/tesseract.js@5.1.1/dist/tesseract.min.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600&display=swap" rel="stylesheet">
    <script>
        tailwind.config = {
            darkMode: 'class',
            theme: {
                extend: {
                    colors: {
                        primary: {
                            400: '#38bdf8', 500: '#0ea5e9', 600: '#0284c7', 700: '#0369a1'
                        },
                        dark: {
                            300: '#cbd5e1', 400: '#94a3b8', 500: '#64748b', 600: '#475569',
                            700: '#334155', 800: '#1e293b', 900: '#0f172a', 950: '#020617'
                        }
                    }
                }
            }
        }
    </script>
    <style>
        .glass {
            background: rgba(30, 41, 59, 0.7);
            backdrop-filter: blur(12px);
            border: 1px solid rgba(51, 65, 85, 0.5);
        }
        .btn-primary {
            background: linear-gradient(135deg, #0284c7 0%, #0ea5e9 100%);
            transition: all 0.2s ease;
        }
        .btn-primary:hover {
            background: linear-gradient(135deg, #0369a1 0%, #0284c7 100%);
            transform: translateY(-1px);
            box-shadow: 0 10px 20px rgba(14, 165, 233, 0.25);
        }
    </style>
</head>
<body class="bg-dark-900 text-white min-h-screen">
    <!-- Status Bar -->
    <header class="glass fixed top-0 left-0 right-0 z-50 border-b border-dark-700/50">
        <div class="container mx-auto px-4 h-16 flex items-center justify-between">
            <div class="flex items-center gap-4">
                <div class="flex items-center gap-2">
                    <div class="w-8 h-8 bg-primary-600 rounded-lg flex items-center justify-center">
                        <svg class="w-5 h-5 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z" />
                        </svg>
                    </div>
                    <span class="font-semibold text-lg">CaptnReverse</span>
                </div>
                <div class="hidden md:flex items-center gap-2">
                    <div id="status-dot" class="w-2 h-2 rounded-full bg-dark-500"></div>
                    <span id="status-text" class="text-sm text-dark-300">Ready</span>
                </div>
            </div>
            <button id="settings-btn" class="p-2 hover:bg-dark-700 rounded-lg transition-colors">
                <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10.325 4.317c.426-1.756 2.924-1.756 3.35 0a1.724 1.724 0 002.573 1.066c1.543-.94 3.31.826 2.37 2.37a1.724 1.724 0 001.065 2.572c1.756.426 1.756 2.924 0 3.35a1.724 1.724 0 00-1.066 2.573c.94 1.543-.826 3.31-2.37 2.37a1.724 1.724 0 00-2.572 1.065c-.426 1.756-2.924 1.756-3.35 0a1.724 1.724 0 00-2.573-1.066c-1.543.94-3.31-.826-2.37-2.37a1.724 1.724 0 00-1.065-2.572c-1.756-.426-1.756-2.924 0-3.35a1.724 1.724 0 001.066-2.573c-.94-1.543.826-3.31 2.37-2.37.996.608 2.296.07 2.572-1.065z" />
                </svg>
            </button>
        </div>
    </header>

    <!-- Main Content -->
    <main class="pt-20 min-h-screen max-h-screen overflow-y-auto bg-gradient-to-br from-dark-900 via-dark-800 to-dark-900">
        <!-- Setup Screen -->
        <div id="setup-screen" class="container mx-auto px-4 py-8 max-w-4xl">
            <!-- Header -->
            <header class="text-center mb-12">
                <div class="inline-flex items-center gap-3 mb-6">
                    <div class="w-16 h-16 bg-primary-600 rounded-2xl flex items-center justify-center">
                        <svg class="w-10 h-10 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 12a3 3 0 11-6 0 3 3 0 016 0z" />
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M2.458 12C3.732 7.943 7.523 5 12 5c4.478 0 8.268 2.943 9.542 7-1.274 4.057-5.064 7-9.542 7-4.477 0-8.268-2.943-9.542-7z" />
                        </svg>
                    </div>
                    <h1 class="text-5xl font-bold bg-gradient-to-r from-primary-400 to-primary-600 bg-clip-text text-transparent">
                        CaptnReverse
                    </h1>
                </div>
                <p class="text-dark-300 text-xl max-w-2xl mx-auto">
                    Advanced OCR and Text-to-Speech powered by cutting-edge browser APIs
                </p>
            </header>

            <!-- Setup Card -->
            <div class="glass rounded-2xl p-8 max-w-2xl mx-auto text-center">
                <div class="w-20 h-20 bg-primary-600/20 rounded-full flex items-center justify-center mx-auto mb-6">
                    <svg class="w-10 h-10 text-primary-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 9a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 0110.07 4h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0018.07 7H19a2 2 0 012 2v9a2 2 0 01-2 2H5a2 2 0 01-2-2V9z" />
                    </svg>
                </div>
                
                <h2 class="text-2xl font-semibold mb-4">Welcome to CaptnReverse</h2>
                <p class="text-dark-300 mb-6">
                    This app uses your camera to read text aloud using advanced OCR technology.
                    We'll need camera permission to get started.
                </p>

                <button id="request-camera" class="btn-primary w-full text-lg py-4 mb-4 rounded-xl font-medium">
                    🚀 Enable Camera Access
                </button>
                
                <button onclick="location.reload()" class="w-full bg-dark-600 hover:bg-dark-500 text-white py-3 px-6 rounded-xl transition-colors text-sm mb-4">
                    🔄 Reset Permissions
                </button>

                <div class="text-sm text-dark-400 space-y-1">
                    <p>✅ No downloads required - runs entirely in your browser</p>
                    <p>🔒 Your data never leaves your device</p>  
                    <p>🚀 Uses cutting-edge Web APIs for optimal performance</p>
                </div>
            </div>

            <!-- Features Grid -->
            <div class="grid md:grid-cols-3 gap-6 mt-12">
                <div class="glass rounded-2xl p-6 text-center">
                    <div class="w-12 h-12 bg-primary-600/20 rounded-xl flex items-center justify-center mx-auto mb-4">
                        <svg class="w-6 h-6 text-primary-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 6.253v13m0-13C10.832 5.477 9.246 5 7.5 5S4.168 5.477 3 6.253v13C4.168 18.477 5.754 18 7.5 18s3.332.477 4.5 1.253m0-13C13.168 5.477 14.754 5 16.5 5c1.746 0 3.332.477 4.5 1.253v13C19.832 18.477 18.246 18 16.5 18c-1.746 0-3.332.477-4.5 1.253" />
                        </svg>
                    </div>
                    <h3 class="font-semibold mb-2 text-white">Advanced OCR</h3>
                    <p class="text-dark-300 text-sm">Tesseract.js with WebAssembly acceleration</p>
                </div>

                <div class="glass rounded-2xl p-6 text-center">
                    <div class="w-12 h-12 bg-primary-600/20 rounded-xl flex items-center justify-center mx-auto mb-4">
                        <svg class="w-6 h-6 text-primary-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                        </svg>
                    </div>
                    <h3 class="font-semibold mb-2 text-white">Natural TTS</h3>
                    <p class="text-dark-300 text-sm">Web Speech API with voice selection</p>
                </div>

                <div class="glass rounded-2xl p-6 text-center">
                    <div class="w-12 h-12 bg-primary-600/20 rounded-xl flex items-center justify-center mx-auto mb-4">
                        <svg class="w-6 h-6 text-primary-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z" />
                        </svg>
                    </div>
                    <h3 class="font-semibold mb-2 text-white">Real-time</h3>
                    <p class="text-dark-300 text-sm">Live processing with intelligent cropping</p>
                </div>
            </div>
        </div>

        <!-- Main App (hidden initially) -->
        <div id="main-app" class="container mx-auto px-4 py-4 max-w-6xl h-[calc(100vh-5rem)] hidden">
            <div class="grid lg:grid-cols-3 gap-4 h-full">
                <!-- Camera View -->
                <div class="lg:col-span-2 space-y-6">
                    <!-- Camera Feed -->
                    <div class="glass rounded-2xl p-6">
                        <div id="camera-container" class="aspect-video bg-dark-800 rounded-xl overflow-hidden relative cursor-crosshair">
                            <video id="camera-feed" autoplay muted playsinline class="w-full h-full object-cover"></video>
                            <canvas id="crop-overlay" class="absolute inset-0 w-full h-full"></canvas>
                            
                            <!-- Crop Instructions Overlay -->
                            <div id="crop-instructions" class="absolute inset-0 flex items-center justify-center pointer-events-none">
                                <div class="glass rounded-xl p-4 text-center">
                                    <p class="text-sm text-dark-300 mb-1">Click and drag to select text area</p>
                                    <p class="text-xs text-dark-400">Crop area will be highlighted in blue</p>
                                </div>
                            </div>
                            
                            <!-- Processing State -->
                            <div id="processing-state" class="absolute inset-0 bg-black/50 flex items-center justify-center hidden">
                                <div class="glass rounded-xl p-6 text-center">
                                    <div class="w-12 h-12 border-4 border-primary-500 border-t-transparent rounded-full animate-spin mx-auto mb-4"></div>
                                    <p class="text-lg font-medium">Processing Text...</p>
                                    <p id="ocr-progress" class="text-sm text-dark-300 mt-2">0%</p>
                                </div>
                            </div>
                        </div>

                        <!-- Camera Controls (directly below camera) -->
                        <div class="space-y-3 mt-4">
                            <!-- Zoom Control -->
                            <div class="flex items-center gap-4">
                                <span class="text-sm font-medium text-dark-300 w-12">Zoom:</span>
                                <input id="camera-zoom" type="range" min="1.0" max="5.0" step="0.1" value="1.0" class="flex-1 h-2 bg-dark-600 rounded-lg">
                                <span id="zoom-value" class="text-sm font-mono text-primary-400 w-12">1.0x</span>
                            </div>
                            
                            <!-- Focus Control -->
                            <div class="flex items-center gap-4">
                                <span class="text-sm font-medium text-dark-300 w-12">Focus:</span>
                                <input id="camera-focus" type="range" min="0" max="1000" step="50" value="500" class="flex-1 h-2 bg-dark-600 rounded-lg">
                                <span id="focus-value" class="text-sm font-mono text-primary-400 w-12">Auto</span>
                                <button id="focus-auto" class="text-xs bg-dark-600 hover:bg-dark-500 px-2 py-1 rounded transition-colors">Auto</button>
                            </div>
                        </div>
                        
                        <!-- Crop Presets -->
                        <div class="flex justify-end mt-4">
                            <div class="flex gap-2">
                                <button onclick="setCrop(0.25, 0.25, 0.5, 0.5)" class="bg-dark-600 hover:bg-dark-500 px-3 py-1 rounded text-xs transition-colors">Center</button>
                                <button onclick="setCrop(0, 0, 1, 0.5)" class="bg-dark-600 hover:bg-dark-500 px-3 py-1 rounded text-xs transition-colors">Top</button>
                                <button onclick="setCrop(0, 0.5, 1, 0.5)" class="bg-dark-600 hover:bg-dark-500 px-3 py-1 rounded text-xs transition-colors">Bottom</button>
                                <button onclick="setCrop(0, 0, 1, 1)" class="bg-dark-600 hover:bg-dark-500 px-3 py-1 rounded text-xs transition-colors">Full</button>
                            </div>
                        </div>

                        <!-- Camera Controls -->
                        <div class="flex items-center justify-between mt-6">
                            <div class="flex items-center gap-2">
                                <div id="camera-status-dot" class="w-2 h-2 rounded-full bg-green-400"></div>
                                <span id="camera-status-text" class="text-sm text-dark-300">Camera active</span>
                            </div>
                            
                            <div class="flex gap-3">
                                <button id="read-now-btn" class="btn-primary px-4 py-2 rounded-lg text-sm font-medium">
                                    📖 Read Now
                                </button>
                                <button id="test-tts-btn" class="bg-purple-600 hover:bg-purple-700 px-4 py-2 rounded-lg text-sm font-medium transition-colors">
                                    🔊 Test TTS
                                </button>
                                <button id="stop-speech-btn" class="bg-red-600 hover:bg-red-700 px-4 py-2 rounded-lg text-sm font-medium transition-colors hidden">
                                    🔇 Stop Speech
                                </button>
                            </div>
                        </div>
                    </div>

                    <!-- Detected Text Display -->
                    <div id="text-display" class="glass rounded-2xl p-6 hidden">
                        <div class="flex items-start justify-between mb-4">
                            <h3 class="text-lg font-semibold text-primary-300">Detected Text</h3>
                            <button id="speak-text-btn" class="p-2 hover:bg-dark-700 rounded-lg transition-colors">
                                <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15.536 8.464a5 5 0 010 7.072M18.364 5.636a9 9 0 010 12.728" />
                                </svg>
                            </button>
                        </div>
                        <p id="detected-text" class="text-dark-100 leading-relaxed text-lg"></p>
                        <div class="mt-4 text-sm text-dark-400">
                            <span>Confidence: <span id="confidence-score">0</span>%</span>
                            <span class="ml-4">Processing time: <span id="processing-time">0</span>ms</span>
                        </div>
                    </div>
                </div>

                <!-- Controls Panel -->
                <div class="space-y-4 overflow-y-auto">
                    <!-- Monitoring Control -->
                    <div class="glass rounded-2xl p-6">
                        <h3 class="text-lg font-semibold mb-4 text-primary-300">Control Center</h3>
                        <button id="monitor-toggle" class="w-full bg-green-600 hover:bg-green-700 text-white font-semibold py-4 px-6 rounded-xl transition-all duration-200 transform hover:scale-105">
                            ▶️ Start Monitoring
                        </button>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <!-- Settings Modal -->
    <div id="settings-modal" class="fixed inset-0 z-50 bg-black/50 backdrop-blur-sm hidden flex items-center justify-center p-4">
        <div class="bg-dark-800 rounded-2xl shadow-2xl border border-dark-700 w-full max-w-2xl max-h-[90vh] overflow-y-auto">
            <!-- Header -->
            <div class="flex items-center justify-between p-6 border-b border-dark-700">
                <h2 class="text-2xl font-semibold">Settings</h2>
                <button id="close-settings" class="p-2 hover:bg-dark-700 rounded-lg transition-colors">
                    <svg class="w-5 h-5" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" />
                    </svg>
                </button>
            </div>

            <div class="p-6 space-y-8">
                <!-- OCR Engine Selection -->
                <section>
                    <h3 class="text-lg font-medium mb-4 text-primary-300">OCR Engine</h3>
                    <div class="flex items-center gap-4 mb-4">
                        <button id="ocr-tesseract" class="flex-1 py-3 px-4 rounded-xl font-medium transition-all bg-primary-600 text-white">
                            Tesseract.js
                        </button>
                        <button id="ocr-paddle" class="flex-1 py-3 px-4 rounded-xl font-medium transition-all bg-dark-600 hover:bg-dark-500 text-white">
                            PaddleOCR
                        </button>
                    </div>
                    <div id="ocr-engine-info" class="text-sm text-dark-400">
                        <p>Tesseract.js - Fast, lightweight, good for general text</p>
                    </div>
                </section>

                <!-- Speech Settings -->
                <section>
                    <h3 class="text-lg font-medium mb-4 text-primary-300">Text-to-Speech</h3>
                    <div class="space-y-4">
                        <div class="flex items-center justify-between">
                            <label class="text-sm font-medium">Auto Read</label>
                            <button id="auto-read-toggle-modal" class="relative inline-flex h-6 w-11 items-center rounded-full transition-colors bg-primary-600">
                                <span class="inline-block h-4 w-4 transform rounded-full bg-white transition translate-x-6"></span>
                            </button>
                        </div>

                        <div>
                            <label class="block text-sm font-medium mb-2">Speech Rate: <span id="rate-value-modal">1.0</span>x</label>
                            <input id="speech-rate-modal" type="range" min="0.5" max="2.0" step="0.1" value="1.0" class="w-full h-2 bg-dark-600 rounded-lg">
                        </div>

                        <div>
                            <label class="block text-sm font-medium mb-2">Speech Volume: <span id="volume-value">100</span>%</label>
                            <input id="speech-volume" type="range" min="0" max="100" step="5" value="100" class="w-full h-2 bg-dark-600 rounded-lg">
                        </div>

                        <div>
                            <label class="block text-sm font-medium mb-2">Voice Selection</label>
                            <select id="voice-select" class="w-full bg-dark-700 border border-dark-600 rounded-lg px-3 py-2 text-white">
                                <option value="">Default Voice</option>
                            </select>
                        </div>
                    </div>
                </section>

                <!-- OCR Settings -->
                <section>
                    <h3 class="text-lg font-medium mb-4 text-primary-300">OCR Settings</h3>
                    <div class="space-y-4">
                        <div>
                            <label class="block text-sm font-medium mb-2">OCR Sensitivity: <span id="sensitivity-value-modal">60</span>%</label>
                            <input id="sensitivity-modal" type="range" min="10" max="100" step="5" value="60" class="w-full h-2 bg-dark-600 rounded-lg">
                        </div>

                        <div>
                            <label class="block text-sm font-medium mb-2">Image Threshold: <span id="threshold-value-modal">150</span></label>
                            <input id="threshold-slider-modal" type="range" min="50" max="250" step="10" value="150" class="w-full h-2 bg-dark-600 rounded-lg">
                        </div>

                        <div>
                            <label class="block text-sm font-medium mb-2">Processing Interval: <span id="interval-value">2000</span>ms</label>
                            <input id="processing-interval" type="range" min="500" max="5000" step="250" value="2000" class="w-full h-2 bg-dark-600 rounded-lg">
                        </div>
                    </div>
                </section>

                <!-- Debug Options -->
                <section>
                    <h3 class="text-lg font-medium mb-4 text-primary-300">Debug Options</h3>
                    <div class="space-y-4">
                        <div class="flex items-center justify-between">
                            <label class="text-sm font-medium">Show Debug Canvas</label>
                            <button id="debug-toggle" class="relative inline-flex h-6 w-11 items-center rounded-full transition-colors bg-primary-600">
                                <span class="inline-block h-4 w-4 transform rounded-full bg-white transition translate-x-6"></span>
                            </button>
                        </div>
                        
                        <button id="test-ocr" class="w-full bg-purple-600 hover:bg-purple-700 text-white py-3 px-4 rounded-xl font-medium transition-colors">
                            🧪 Test OCR with Sample Text
                        </button>

                        <button id="release-camera" class="w-full bg-red-600 hover:bg-red-700 text-white py-3 px-4 rounded-xl font-medium transition-colors">
                            🛑 Release Camera Resources
                        </button>
                    </div>
                </section>
            </div>
        </div>
    </div>

    <script>
        console.log('🚀 CaptnReverse initializing...');
        
        // Global state
        let isMonitoring = false;
        let stream = null;
        let ocrWorker = null;
        let currentCrop = { x: 0.25, y: 0.25, width: 0.5, height: 0.5 };
        let autoRead = true;
        let speechRate = 1.0;
        let sensitivity = 60; // Increased default for better quality filtering
        let lastText = '';
        let cameraZoom = 1.0;
        let mediaStreamTrack = null;
        let imageThreshold = 150;
        let currentOCREngine = 'tesseract'; // 'tesseract' or 'paddle'
        let paddleOCRLoaded = false;
        let showDebugCanvas = true;
        let processingInterval = 2000;
        let cameraRequestInProgress = false;

        // Initialize app
        async function init() {
            console.log('🔧 Setting up event listeners...');
            setupEventListeners();
            await initOCR();
            checkSecureContext();
            console.log('✅ CaptnReverse ready!');
        }

        function checkSecureContext() {
            if (!window.isSecureContext) {
                console.warn('⚠️ Not in secure context - camera may not work');
                const setupCard = document.querySelector('#setup-screen .glass');
                setupCard.innerHTML = `
                    <div class="w-20 h-20 bg-yellow-600/20 rounded-full flex items-center justify-center mx-auto mb-6">
                        <svg class="w-10 h-10 text-yellow-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-2.5L13.732 4c-.77-.833-2.694-.833-3.464 0L3.34 16.5c-.77.833.192 2.5 1.732 2.5z" />
                        </svg>
                    </div>
                    <h2 class="text-2xl font-semibold mb-4 text-yellow-300">HTTPS Required</h2>
                    <p class="text-dark-300 mb-6">Camera access requires a secure connection (HTTPS) or localhost. Please access the app via HTTPS or localhost for full functionality.</p>
                    <div class="text-sm text-dark-400 space-y-1">
                        <p>💡 Try: https://localhost:3000 (if you have SSL)</p>
                        <p>🔧 Or use: http://127.0.0.1:3000</p>
                        <p>🌐 For production: Deploy to HTTPS hosting</p>
                    </div>
                `;
            } else {
                console.log('✅ Secure context confirmed - camera should work');
            }
        }

        function setupEventListeners() {
            // Camera permission
            document.getElementById('request-camera').addEventListener('click', requestCamera);
            
            // Monitoring toggle
            document.getElementById('monitor-toggle').addEventListener('click', toggleMonitoring);
            
            // Read now
            document.getElementById('read-now-btn').addEventListener('click', readNow);
            
            // Test TTS
            document.getElementById('test-tts-btn').addEventListener('click', () => {
                speak("CaptnReverse text-to-speech is working perfectly! This is a test of the speech synthesis system.");
            });
            
            // Stop speech
            document.getElementById('stop-speech-btn').addEventListener('click', () => {
                speechSynthesis.cancel();
                document.getElementById('stop-speech-btn').classList.add('hidden');
                updateStatus(isMonitoring ? 'Monitoring active' : 'Ready', 'bg-green-400');
            });

            // Speak detected text button
            document.getElementById('speak-text-btn').addEventListener('click', () => {
                const text = document.getElementById('detected-text').textContent;
                if (text) speak(text);
            });

            // Settings modal
            document.getElementById('settings-btn').addEventListener('click', () => {
                document.getElementById('settings-modal').classList.remove('hidden');
                populateVoiceSelect();
            });
            
            document.getElementById('close-settings').addEventListener('click', () => {
                document.getElementById('settings-modal').classList.add('hidden');
            });

            // Camera zoom
            document.getElementById('camera-zoom').addEventListener('input', (e) => {
                cameraZoom = parseFloat(e.target.value);
                document.getElementById('zoom-value').textContent = cameraZoom.toFixed(1);
                applyCameraZoom();
            });

            // Camera focus
            document.getElementById('camera-focus').addEventListener('input', (e) => {
                const focusDistance = parseInt(e.target.value);
                document.getElementById('focus-value').textContent = focusDistance === 500 ? 'Auto' : focusDistance;
                applyCameraFocus(focusDistance);
            });

            // Auto focus button
            document.getElementById('focus-auto').addEventListener('click', () => {
                document.getElementById('camera-focus').value = 500;
                document.getElementById('focus-value').textContent = 'Auto';
                applyCameraFocus(500);
            });

            // Crop selector
            setupCropSelector();
            setupSettingsEventListeners();
        }

        function setupSettingsEventListeners() {
            // OCR Engine toggle
            document.getElementById('ocr-tesseract').addEventListener('click', () => switchOCREngine('tesseract'));
            document.getElementById('ocr-paddle').addEventListener('click', () => switchOCREngine('paddle'));

            // Auto-read toggle (modal)
            document.getElementById('auto-read-toggle-modal').addEventListener('click', () => {
                autoRead = !autoRead;
                updateAutoReadToggle();
                updateModalAutoReadToggle();
            });

            // Speech settings (modal)
            document.getElementById('speech-rate-modal').addEventListener('input', (e) => {
                speechRate = parseFloat(e.target.value);
                document.getElementById('rate-value-modal').textContent = speechRate;
            });

            document.getElementById('speech-volume').addEventListener('input', (e) => {
                const volume = parseInt(e.target.value);
                document.getElementById('volume-value').textContent = volume;
                // Volume will be applied in speak function
            });

            // OCR settings (modal)
            document.getElementById('sensitivity-modal').addEventListener('input', (e) => {
                sensitivity = parseInt(e.target.value);
                document.getElementById('sensitivity-value-modal').textContent = sensitivity;
            });

            document.getElementById('threshold-slider-modal').addEventListener('input', (e) => {
                imageThreshold = parseInt(e.target.value);
                document.getElementById('threshold-value-modal').textContent = imageThreshold;
            });

            document.getElementById('processing-interval').addEventListener('input', (e) => {
                processingInterval = parseInt(e.target.value);
                document.getElementById('interval-value').textContent = processingInterval;
                if (isMonitoring) {
                    stopMonitoring();
                    startMonitoring(); // Restart with new interval
                }
            });

            // Debug toggle
            document.getElementById('debug-toggle').addEventListener('click', () => {
                showDebugCanvas = !showDebugCanvas;
                updateDebugToggle();
                if (!showDebugCanvas) {
                    // Remove debug elements
                    const elements = ['debug-canvas', 'debug-label', 'debug-text'];
                    elements.forEach(id => {
                        const el = document.getElementById(id);
                        if (el) el.remove();
                    });
                }
            });

            // Release camera button
            document.getElementById('release-camera').addEventListener('click', () => {
                cleanupCamera();
                // Reset UI to setup screen
                document.getElementById('main-app').classList.add('hidden');
                document.getElementById('setup-screen').classList.remove('hidden');
                document.getElementById('settings-modal').classList.add('hidden');
                updateStatus('Camera released', 'bg-yellow-400');
            });
        }

        function updateAutoReadToggle() {
            const toggle = document.getElementById('auto-read-toggle');
            const thumb = toggle.querySelector('span');
            
            if (autoRead) {
                toggle.classList.add('bg-primary-600');
                toggle.classList.remove('bg-dark-600');
                thumb.classList.add('translate-x-6');
                thumb.classList.remove('translate-x-1');
            } else {
                toggle.classList.remove('bg-primary-600');
                toggle.classList.add('bg-dark-600');
                thumb.classList.remove('translate-x-6');
                thumb.classList.add('translate-x-1');
            }
        }

        function setupCropSelector() {
            const container = document.getElementById('camera-container');
            let isDragging = false;
            let startX = 0, startY = 0;

            container.addEventListener('mousedown', (e) => {
                e.preventDefault();
                const rect = container.getBoundingClientRect();
                startX = (e.clientX - rect.left) / rect.width;
                startY = (e.clientY - rect.top) / rect.height;
                isDragging = true;
                
                // Hide instructions when user starts interacting
                document.getElementById('crop-instructions').style.opacity = '0';
            });

            container.addEventListener('mousemove', (e) => {
                if (!isDragging) return;
                e.preventDefault();
                
                const rect = container.getBoundingClientRect();
                const endX = (e.clientX - rect.left) / rect.width;
                const endY = (e.clientY - rect.top) / rect.height;

                currentCrop = {
                    x: Math.min(startX, endX),
                    y: Math.min(startY, endY),
                    width: Math.abs(endX - startX),
                    height: Math.abs(endY - startY)
                };

                updateCropDisplay();
            });

            container.addEventListener('mouseup', () => {
                isDragging = false;
                // Save crop to localStorage
                localStorage.setItem('captn-reverse-crop', JSON.stringify(currentCrop));
            });

            container.addEventListener('mouseleave', () => {
                isDragging = false;
            });

            // Touch support for mobile
            container.addEventListener('touchstart', (e) => {
                e.preventDefault();
                const touch = e.touches[0];
                const rect = container.getBoundingClientRect();
                startX = (touch.clientX - rect.left) / rect.width;
                startY = (touch.clientY - rect.top) / rect.height;
                isDragging = true;
                document.getElementById('crop-instructions').style.opacity = '0';
            });

            container.addEventListener('touchmove', (e) => {
                if (!isDragging) return;
                e.preventDefault();
                
                const touch = e.touches[0];
                const rect = container.getBoundingClientRect();
                const endX = (touch.clientX - rect.left) / rect.width;
                const endY = (touch.clientY - rect.top) / rect.height;

                currentCrop = {
                    x: Math.min(startX, endX),
                    y: Math.min(startY, endY),
                    width: Math.abs(endX - startX),
                    height: Math.abs(endY - startY)
                };

                updateCropDisplay();
            });

            container.addEventListener('touchend', () => {
                isDragging = false;
                localStorage.setItem('captn-reverse-crop', JSON.stringify(currentCrop));
            });

            // Load saved crop or show default
            const savedCrop = localStorage.getItem('captn-reverse-crop');
            if (savedCrop) {
                try {
                    currentCrop = JSON.parse(savedCrop);
                } catch (e) {
                    setCrop(0.25, 0.25, 0.5, 0.5);
                }
            } else {
                setCrop(0.25, 0.25, 0.5, 0.5);
            }
        }

        function setCrop(x, y, width, height) {
            currentCrop = { x, y, width, height };
            // Hide instructions once user selects a crop area
            document.getElementById('crop-instructions').style.opacity = '0';
            localStorage.setItem('captn-reverse-crop', JSON.stringify(currentCrop));
        }

        function showDebugCanvas(canvas) {
            // Remove any existing debug elements
            const existingCanvas = document.getElementById('debug-canvas');
            const existingLabel = document.getElementById('debug-label');
            const existingText = document.getElementById('debug-text');
            if (existingCanvas) existingCanvas.remove();
            if (existingLabel) existingLabel.remove();
            if (existingText) existingText.remove();
            
            // Create debug display - this should show ONLY the cropped area
            const debugCanvas = document.createElement('canvas');
            const debugCtx = debugCanvas.getContext('2d');
            
            // Copy the processed canvas exactly as it will be sent to OCR
            debugCanvas.width = canvas.width;
            debugCanvas.height = canvas.height;
            debugCtx.drawImage(canvas, 0, 0);
            
            debugCanvas.id = 'debug-canvas';
            debugCanvas.style.position = 'fixed';
            debugCanvas.style.top = '80px';
            debugCanvas.style.right = '10px';
            debugCanvas.style.maxWidth = '200px';
            debugCanvas.style.maxHeight = '150px';
            debugCanvas.style.border = '2px solid #0ea5e9';
            debugCanvas.style.borderRadius = '8px';
            debugCanvas.style.zIndex = '9999';
            debugCanvas.style.background = 'white';
            debugCanvas.style.imageRendering = 'pixelated'; // Show crisp pixels
            
            document.body.appendChild(debugCanvas);
            
            // Add label
            const label = document.createElement('div');
            label.id = 'debug-label';
            label.textContent = `Debug: OCR Input (${canvas.width}×${canvas.height}px)`;
            label.style.position = 'fixed';
            label.style.top = '60px';
            label.style.right = '10px';
            label.style.color = '#0ea5e9';
            label.style.fontSize = '12px';
            label.style.fontWeight = 'bold';
            label.style.zIndex = '9999';
            label.style.textShadow = '0 0 4px black';
            document.body.appendChild(label);
            
            // Add text display area for debug
            const textDisplay = document.createElement('div');
            textDisplay.id = 'debug-text';
            textDisplay.style.position = 'fixed';
            textDisplay.style.top = '250px';
            textDisplay.style.right = '10px';
            textDisplay.style.maxWidth = '200px';
            textDisplay.style.background = 'rgba(15, 23, 42, 0.9)';
            textDisplay.style.color = '#0ea5e9';
            textDisplay.style.padding = '8px';
            textDisplay.style.borderRadius = '8px';
            textDisplay.style.fontSize = '11px';
            textDisplay.style.border = '1px solid #0ea5e9';
            textDisplay.style.zIndex = '9999';
            textDisplay.textContent = 'Waiting for OCR result...';
            document.body.appendChild(textDisplay);
            
            console.log(`🔍 Debug canvas: ${canvas.width}×${canvas.height}px - this exact image goes to OCR`);
        }

        function updateDebugText(text, confidence) {
            const debugText = document.getElementById('debug-text');
            if (debugText) {
                debugText.innerHTML = `
                    <strong>OCR Result:</strong><br>
                    "${text}"<br>
                    <small>Confidence: ${Math.round(confidence)}%</small>
                `;
            }
        }

        async function initOCR() {
            try {
                console.log('🤖 Initializing OCR worker...');
                ocrWorker = await Tesseract.createWorker('eng', 1, {
                    logger: ({ status, progress }) => {
                        if (status === 'recognizing text') {
                            const progressEl = document.getElementById('ocr-progress');
                            if (progressEl) {
                                progressEl.textContent = `${Math.round(progress * 100)}%`;
                            }
                        }
                    }
                });

                await ocrWorker.setParameters({
                    tessedit_pageseg_mode: '1', // OPTIMAL: Auto with OSD - 70% confidence on test image!
                    preserve_interword_spaces: '1' // Better word spacing
                });

                console.log('✅ OCR Worker ready');
            } catch (error) {
                console.error('❌ OCR initialization failed:', error);
            }
        }

        async function requestCamera() {
            try {
                // Prevent duplicate camera requests
                if (cameraRequestInProgress) {
                    console.log('⏳ Camera request already in progress...');
                    return;
                }

                cameraRequestInProgress = true;
                console.log('📸 Requesting camera permission...');
                
                // Cleanup any existing stream first
                if (stream) {
                    console.log('🧹 Cleaning up existing camera stream...');
                    stream.getTracks().forEach(track => track.stop());
                    stream = null;
                    mediaStreamTrack = null;
                }
                
                // Request camera permission with simplified constraints for better compatibility
                stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 1920 },
                        height: { ideal: 1080 }
                    }
                });

                console.log('✅ Camera permission granted!');
                cameraRequestInProgress = false;
                showMainApp();

            } catch (error) {
                cameraRequestInProgress = false;
                console.error('❌ Camera access denied:', error);
                
                let errorMessage = 'Camera access is required for CaptnReverse to function.';
                
                if (error.name === 'NotAllowedError') {
                    errorMessage = 'Camera permission was denied. Please refresh the page and allow camera access.';
                } else if (error.name === 'NotFoundError') {
                    errorMessage = 'No camera found. Please connect a camera and try again.';
                } else if (error.name === 'NotSupportedError') {
                    errorMessage = 'Camera is not supported in this browser. Try Chrome or Edge.';
                } else {
                    errorMessage = `Camera error: ${error.message}`;
                }
                
                // Update UI to show error
                const setupCard = document.querySelector('#setup-screen .glass');
                setupCard.innerHTML = `
                    <div class="w-20 h-20 bg-red-600/20 rounded-full flex items-center justify-center mx-auto mb-6">
                        <svg class="w-10 h-10 text-red-400" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01m-6.938 4h13.856c1.54 0 2.502-1.667 1.732-2.5L13.732 4c-.77-.833-2.694-.833-3.464 0L3.34 16.5c-.77.833.192 2.5 1.732 2.5z" />
                        </svg>
                    </div>
                    <h2 class="text-2xl font-semibold mb-4 text-red-300">Camera Access Required</h2>
                    <p class="text-dark-300 mb-6">${errorMessage}</p>
                    <button id="retry-camera" class="btn-primary w-full text-lg py-4 mb-4">
                        🔄 Try Again
                    </button>
                    <div class="text-sm text-dark-400 space-y-1">
                        <p>💡 Make sure you're using HTTPS or localhost</p>
                        <p>🔒 Your privacy is protected - all processing is local</p>
                        <p>🌐 Works best in Chrome, Edge, or Firefox</p>
                    </div>
                `;
                
                // Add retry event listener
                document.getElementById('retry-camera').addEventListener('click', requestCamera);
            }
        }

        function showMainApp() {
            const video = document.getElementById('camera-feed');
            video.srcObject = stream;
            
            // Get camera track for zoom control
            mediaStreamTrack = stream.getVideoTracks()[0];
            
            // Wait for video to start playing
            video.onloadedmetadata = () => {
                console.log('📹 Video metadata loaded, starting overlay');
                startCropOverlay();
            };
            
            // Hide setup, show main app
            document.getElementById('setup-screen').classList.add('hidden');
            document.getElementById('main-app').classList.remove('hidden');
            
            updateStatus('Camera active', 'bg-green-400');
        }

        async function applyCameraZoom() {
            if (!mediaStreamTrack) return;
            
            try {
                const capabilities = mediaStreamTrack.getCapabilities();
                if (capabilities.zoom) {
                    await mediaStreamTrack.applyConstraints({
                        zoom: { ideal: cameraZoom }
                    });
                    console.log(`📷 Applied zoom: ${cameraZoom}x`);
                }
            } catch (error) {
                console.warn('⚠️ Camera zoom not supported:', error);
            }
        }

        async function applyCameraFocus(focusDistance) {
            if (!mediaStreamTrack) return;
            
            try {
                const capabilities = mediaStreamTrack.getCapabilities();
                console.log('📷 Camera capabilities:', capabilities);
                
                if (capabilities.focusDistance) {
                    const constraints = focusDistance === 500 ? 
                        { focusMode: 'auto' } : 
                        { 
                            focusMode: 'manual',
                            focusDistance: { ideal: focusDistance / 1000 } // Convert to 0-1 range
                        };
                    
                    await mediaStreamTrack.applyConstraints({ advanced: [constraints] });
                    console.log(`🎯 Applied focus: ${focusDistance === 500 ? 'auto' : focusDistance}`);
                } else {
                    console.warn('⚠️ Manual focus not supported on this camera');
                }
            } catch (error) {
                console.warn('⚠️ Focus control error:', error);
            }
        }

        function startCropOverlay() {
            const video = document.getElementById('camera-feed');
            const canvas = document.getElementById('crop-overlay');
            const ctx = canvas.getContext('2d');
            
            function drawOverlay() {
                if (video.videoWidth === 0 || video.videoHeight === 0) {
                    requestAnimationFrame(drawOverlay);
                    return;
                }
                
                // Set canvas size to match video
                const rect = video.getBoundingClientRect();
                canvas.width = rect.width;
                canvas.height = rect.height;
                
                // Clear canvas
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                // Draw semi-transparent overlay
                ctx.fillStyle = 'rgba(0, 0, 0, 0.5)';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                
                // Clear crop area
                const x = currentCrop.x * canvas.width;
                const y = currentCrop.y * canvas.height;
                const width = currentCrop.width * canvas.width;
                const height = currentCrop.height * canvas.height;
                
                ctx.clearRect(x, y, width, height);
                
                // Draw crop border
                ctx.strokeStyle = '#0ea5e9';
                ctx.lineWidth = 3;
                ctx.strokeRect(x, y, width, height);
                
                // Draw corner handles
                const handleSize = 8;
                ctx.fillStyle = '#0ea5e9';
                ctx.fillRect(x - handleSize/2, y - handleSize/2, handleSize, handleSize);
                ctx.fillRect(x + width - handleSize/2, y - handleSize/2, handleSize, handleSize);
                ctx.fillRect(x - handleSize/2, y + height - handleSize/2, handleSize, handleSize);
                ctx.fillRect(x + width - handleSize/2, y + height - handleSize/2, handleSize, handleSize);
                
                requestAnimationFrame(drawOverlay);
            }
            
            drawOverlay();
        }

        function toggleMonitoring() {
            isMonitoring = !isMonitoring;
            const btn = document.getElementById('monitor-toggle');
            
            if (isMonitoring) {
                btn.textContent = '⏸️ Pause Monitoring';
                btn.classList.remove('bg-green-600', 'hover:bg-green-700');
                btn.classList.add('bg-red-600', 'hover:bg-red-700');
                updateStatus('Monitoring active', 'bg-green-400 animate-pulse');
                startMonitoring();
            } else {
                btn.textContent = '▶️ Start Monitoring';
                btn.classList.remove('bg-red-600', 'hover:bg-red-700');
                btn.classList.add('bg-green-600', 'hover:bg-green-700');
                updateStatus('Monitoring paused', 'bg-yellow-400');
                stopMonitoring();
            }
        }

        function startMonitoring() {
            if (!stream || !ocrWorker) return;
            
            window.monitoringInterval = setInterval(async () => {
                await processFrame();
            }, processingInterval); // Use configurable interval
        }

        function stopMonitoring() {
            if (window.monitoringInterval) {
                clearInterval(window.monitoringInterval);
                window.monitoringInterval = null;
            }
        }

        async function readNow() {
            if (!stream || !ocrWorker) return;
            await processFrame();
        }

        async function processFrame() {
            try {
                const video = document.getElementById('camera-feed');
                const canvas = document.createElement('canvas');
                const ctx = canvas.getContext('2d');

                canvas.width = video.videoWidth;
                canvas.height = video.videoHeight;
                
                if (canvas.width === 0 || canvas.height === 0) return;

                ctx.drawImage(video, 0, 0);

                // Apply crop based on video dimensions and crop area
                const cropCanvas = document.createElement('canvas');
                const cropCtx = cropCanvas.getContext('2d');
                
                // Get actual video element dimensions for proper crop calculation
                const videoEl = document.getElementById('camera-feed');
                const videoRect = videoEl.getBoundingClientRect();
                
                // Calculate crop coordinates based on video's actual dimensions
                const scaleX = canvas.width / videoRect.width;
                const scaleY = canvas.height / videoRect.height;
                
                const cropX = currentCrop.x * canvas.width;
                const cropY = currentCrop.y * canvas.height;  
                const cropWidth = currentCrop.width * canvas.width;
                const cropHeight = currentCrop.height * canvas.height;

                console.log(`🔲 Crop area: x=${Math.round(cropX)}, y=${Math.round(cropY)}, w=${Math.round(cropWidth)}, h=${Math.round(cropHeight)}`);
                console.log(`📐 Video: ${canvas.width}x${canvas.height}, Display: ${Math.round(videoRect.width)}x${Math.round(videoRect.height)}`);

                // Set crop canvas to exact crop size
                cropCanvas.width = Math.max(cropWidth, 50); // Minimum 50px width
                cropCanvas.height = Math.max(cropHeight, 50); // Minimum 50px height
                
                // Draw only the cropped portion
                cropCtx.drawImage(canvas, cropX, cropY, cropWidth, cropHeight, 0, 0, cropCanvas.width, cropCanvas.height);

                // OPTIMIZATION: Rescale cropCanvas for optimal OCR resolution (20-40px character height)
                const OCR_TARGET_HEIGHT = 800; // Optimal height for Tesseract.js accuracy
                if (cropCanvas.height > 0 && cropCanvas.height !== OCR_TARGET_HEIGHT) {
                    const aspectRatio = cropCanvas.width / cropCanvas.height;
                    const scaledWidth = OCR_TARGET_HEIGHT * aspectRatio;
                    
                    const tempCanvas = document.createElement('canvas');
                    tempCanvas.width = scaledWidth;
                    tempCanvas.height = OCR_TARGET_HEIGHT;
                    const tempCtx = tempCanvas.getContext('2d');
                    
                    // Scale the cropped image to optimal resolution
                    tempCtx.drawImage(cropCanvas, 0, 0, tempCanvas.width, tempCanvas.height);
                    
                    // Copy scaled image back to cropCanvas
                    cropCanvas.width = tempCanvas.width;
                    cropCanvas.height = tempCanvas.height;
                    cropCtx.drawImage(tempCanvas, 0, 0);
                    
                    console.log(`📏 Scaled crop to optimal OCR size: ${Math.round(scaledWidth)}×${OCR_TARGET_HEIGHT}px`);
                }

                // *** CRITICAL: Image preprocessing for OCR ***
                const imageData = cropCtx.getImageData(0, 0, cropCanvas.width, cropCanvas.height);
                const data = imageData.data;

                // Convert to grayscale and apply binarization (thresholding)
                for (let i = 0; i < data.length; i += 4) {
                    // Grayscale conversion (simple average)
                    const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
                    
                    // Binarization - use adjustable threshold for different lighting conditions  
                    const value = avg > imageThreshold ? 255 : 0;
                    
                    data[i] = value;     // Red
                    data[i + 1] = value; // Green  
                    data[i + 2] = value; // Blue
                    // Alpha channel (data[i + 3]) remains unchanged
                }
                
                // Apply the processed image data back to canvas
                cropCtx.putImageData(imageData, 0, 0);

                // DEBUG: Show processed crop image (if enabled)
                if (showDebugCanvas) {
                    showDebugCanvas(cropCanvas);
                }

                // Show processing state
                document.getElementById('processing-state').classList.remove('hidden');

                const startTime = Date.now();
                const result = await ocrWorker.recognize(cropCanvas);
                const processingTime = Date.now() - startTime;

                // Hide processing state
                document.getElementById('processing-state').classList.add('hidden');

                const ocrText = result.data.text.trim();
                const ocrConfidence = result.data.confidence;
                
                console.log(`🔍 OCR Result: "${ocrText}" (confidence: ${Math.round(ocrConfidence)}%)`);
                
                // Update debug display with OCR result
                updateDebugText(ocrText, ocrConfidence);
                
                if (ocrConfidence > sensitivity) {
                    const text = result.data.text.trim();
                    if (text && text.length > 2 && text !== lastText) {
                        displayText(text, result.data.confidence, processingTime);
                        lastText = text;
                        
                        console.log(`📝 New text detected: "${text}"`);
                        
                        if (autoRead) {
                            console.log(`🔊 Auto-reading enabled, speaking text...`);
                            speak(text);
                        }
                    } else if (text === lastText) {
                        console.log(`🔄 Same text as before, skipping...`);
                    } else {
                        console.log(`📏 Text too short (${text.length} chars), skipping...`);
                    }
                } else {
                    console.log(`🎯 Confidence ${Math.round(result.data.confidence)}% below threshold ${sensitivity}%`);
                }
            } catch (error) {
                document.getElementById('processing-state').classList.add('hidden');
                console.error('❌ OCR processing error:', error);
            }
        }

        function displayText(text, confidence, processingTime) {
            document.getElementById('detected-text').textContent = text;
            document.getElementById('confidence-score').textContent = Math.round(confidence);
            document.getElementById('processing-time').textContent = processingTime;
            document.getElementById('text-display').classList.remove('hidden');
        }

        function speak(text) {
            if (!text || !text.trim()) return;
            
            // Cancel any current speech
            speechSynthesis.cancel();
            
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = speechRate;
            utterance.pitch = 1.0;
            utterance.volume = 1.0;
            
            // Try to get a voice
            const voices = speechSynthesis.getVoices();
            if (voices.length > 0) {
                // Prefer English voices
                const englishVoice = voices.find(voice => voice.lang.startsWith('en')) || voices[0];
                utterance.voice = englishVoice;
            }

            utterance.onstart = () => {
                console.log('🔊 Speaking:', text.substring(0, 50) + '...');
                document.getElementById('stop-speech-btn').classList.remove('hidden');
                updateStatus('Speaking...', 'bg-blue-400 animate-pulse');
            };
            
            utterance.onend = () => {
                console.log('🔇 Speech completed');
                document.getElementById('stop-speech-btn').classList.add('hidden');
                updateStatus(isMonitoring ? 'Monitoring active' : 'Ready', 'bg-green-400');
            };
            
            utterance.onerror = (event) => {
                console.error('🔇 Speech error:', event.error);
                document.getElementById('stop-speech-btn').classList.add('hidden');
                updateStatus('Speech error', 'bg-red-400');
            };

            // Ensure voices are loaded before speaking
            if (voices.length === 0) {
                speechSynthesis.addEventListener('voiceschanged', () => {
                    speechSynthesis.speak(utterance);
                }, { once: true });
            } else {
                speechSynthesis.speak(utterance);
            }
        }

        function updateStatus(text, dotClass) {
            document.getElementById('status-text').textContent = text;
            const dot = document.getElementById('status-dot');
            dot.className = `w-2 h-2 rounded-full ${dotClass}`;
        }

        async function switchOCREngine(engine) {
            console.log(`🔄 Switching to ${engine} OCR engine...`);
            currentOCREngine = engine;
            
            // Update UI
            const tesseractBtn = document.getElementById('ocr-tesseract');
            const paddleBtn = document.getElementById('ocr-paddle');
            const infoDiv = document.getElementById('ocr-engine-info');
            
            if (engine === 'tesseract') {
                tesseractBtn.className = 'flex-1 py-3 px-4 rounded-xl font-medium transition-all bg-primary-600 text-white';
                paddleBtn.className = 'flex-1 py-3 px-4 rounded-xl font-medium transition-all bg-dark-600 hover:bg-dark-500 text-white';
                infoDiv.innerHTML = '<p>Tesseract.js - Fast, lightweight, good for general text</p>';
                
                // Initialize Tesseract if needed
                if (!ocrWorker) {
                    await initOCR();
                }
            } else {
                tesseractBtn.className = 'flex-1 py-3 px-4 rounded-xl font-medium transition-all bg-dark-600 hover:bg-dark-500 text-white';
                paddleBtn.className = 'flex-1 py-3 px-4 rounded-xl font-medium transition-all bg-primary-600 text-white';
                infoDiv.innerHTML = '<p>PaddleOCR - Higher accuracy, larger download, slower processing</p>';
                
                // Load PaddleOCR dynamically
                await loadPaddleOCR();
            }
        }

        async function loadPaddleOCR() {
            if (paddleOCRLoaded) return;
            
            try {
                updateStatus('Loading PaddleOCR...', 'bg-yellow-400 animate-pulse');
                
                // Dynamically load PaddleOCR.js
                const script = document.createElement('script');
                script.src = 'https://unpkg.com/paddleocr@1.0.0/dist/paddleocr.min.js';
                script.onload = () => {
                    console.log('✅ PaddleOCR loaded successfully');
                    paddleOCRLoaded = true;
                    updateStatus('PaddleOCR ready', 'bg-green-400');
                };
                script.onerror = () => {
                    console.error('❌ Failed to load PaddleOCR');
                    updateStatus('PaddleOCR load failed', 'bg-red-400');
                    // Fallback to Tesseract
                    switchOCREngine('tesseract');
                };
                document.head.appendChild(script);
                
            } catch (error) {
                console.error('❌ PaddleOCR loading error:', error);
                updateStatus('OCR error', 'bg-red-400');
                switchOCREngine('tesseract');
            }
        }

        function populateVoiceSelect() {
            const select = document.getElementById('voice-select');
            const voices = speechSynthesis.getVoices();
            
            select.innerHTML = '<option value="">Default Voice</option>';
            
            voices.forEach((voice, index) => {
                const option = document.createElement('option');
                option.value = index;
                option.textContent = `${voice.name} (${voice.lang})`;
                select.appendChild(option);
            });
        }

        function updateModalAutoReadToggle() {
            const toggle = document.getElementById('auto-read-toggle-modal');
            const thumb = toggle.querySelector('span');
            
            if (autoRead) {
                toggle.classList.add('bg-primary-600');
                toggle.classList.remove('bg-dark-600');
                thumb.classList.add('translate-x-6');
                thumb.classList.remove('translate-x-1');
            } else {
                toggle.classList.remove('bg-primary-600');
                toggle.classList.add('bg-dark-600');
                thumb.classList.remove('translate-x-6');
                thumb.classList.add('translate-x-1');
            }
        }

        function updateDebugToggle() {
            const toggle = document.getElementById('debug-toggle');
            const thumb = toggle.querySelector('span');
            
            if (showDebugCanvas) {
                toggle.classList.add('bg-primary-600');
                toggle.classList.remove('bg-dark-600');
                thumb.classList.add('translate-x-6');
                thumb.classList.remove('translate-x-1');
            } else {
                toggle.classList.remove('bg-primary-600');
                toggle.classList.add('bg-dark-600');
                thumb.classList.remove('translate-x-6');
                thumb.classList.add('translate-x-1');
            }
        }

        // Cleanup camera resources on page unload
        function cleanupCamera() {
            console.log('🧹 Cleaning up camera resources...');
            
            if (stream) {
                // Stop all tracks to release camera
                stream.getTracks().forEach(track => {
                    console.log(`🛑 Stopping track: ${track.kind} (${track.label})`);
                    track.stop();
                });
                stream = null;
                mediaStreamTrack = null;
            }

            // Stop monitoring
            if (window.monitoringInterval) {
                clearInterval(window.monitoringInterval);
                window.monitoringInterval = null;
            }

            // Cleanup OCR worker
            if (ocrWorker) {
                ocrWorker.terminate().catch(e => console.warn('OCR cleanup error:', e));
                ocrWorker = null;
            }

            console.log('✅ Camera resources cleaned up');
        }

        // Critical: Add multiple cleanup event listeners
        window.addEventListener('beforeunload', cleanupCamera);
        window.addEventListener('unload', cleanupCamera);
        window.addEventListener('pagehide', cleanupCamera);
        document.addEventListener('visibilitychange', () => {
            if (document.hidden) {
                console.log('📱 Page hidden, cleaning up camera...');
                cleanupCamera();
            }
        });

        // Cleanup on focus loss (important for mobile)
        window.addEventListener('blur', () => {
            console.log('👁️ Window lost focus, pausing camera...');
            if (isMonitoring) {
                toggleMonitoring(); // Stop monitoring to reduce resource usage
            }
        });

        // Initialize when page loads
        document.addEventListener('DOMContentLoaded', init);

        // Live reload for development
        if (location.hostname === 'localhost') {
            let lastModified = null;
            setInterval(async () => {
                try {
                    const response = await fetch(location.href, { method: 'HEAD' });
                    const modified = response.headers.get('Last-Modified');
                    if (lastModified && modified !== lastModified) {
                        location.reload();
                    }
                    lastModified = modified;
                } catch (error) {
                    // Ignore
                }
            }, 3000);
        }
    </script>
</body>
</html>